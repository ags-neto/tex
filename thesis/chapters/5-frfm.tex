\chapter{Development of the Full-Reference Metric}

\section{Introduction}

This chapter outlines the development of a Full-Reference Fusion Metric (FRFM), a novel IQA metric designed to align with human perception. By synthesizing the strengths of multiple objective metrics, the FRFM bridges the gap between subjective Mean Opinion Scores (MOS) and computational evaluations. The chapter details the selection, fusion, and validation processes that underpin the metric's development.

\section{Metric Selection}

The first step in developing the FRFM involves identifying metrics that exhibit high correlation with MOS data. A comprehensive analysis of 50 metrics, including traditional, no-reference, and learning-based methods, was performed. The metrics with the strongest correlations were shortlisted for the fusion process.

\subsection{Correlation Analysis}

Metrics were evaluated using Pearson, Spearman, and Kendall’s Tau correlation coefficients. The analysis revealed the following metrics as the most aligned with MOS:
\begin{itemize}
    \item Structural Similarity Index (SSIM) (Wang et al., 2004)
    \item Learned Perceptual Image Patch Similarity (LPIPS) (Zhang et al., 2018)
    \item Visual Information Fidelity (VIF) (Sheikh and Bovik, 2006)
    \item Perceptual Adversarial Similarity Score (PASS) (Liu et al., 2021)
\end{itemize}

These metrics were selected for their complementary strengths:
\begin{itemize}
    \item SSIM captures structural similarities, making it effective for standard distortions.
    \item LPIPS leverages deep feature representations, aligning well with human perception of complex artifacts.
    \item VIF quantifies the preservation of visual information.
    \item PASS excels at detecting perceptual changes in steganographic and adversarial contexts.
\end{itemize}

\section{Fusion Methodology}

The selected metrics were integrated into a unified framework using a weighted fusion approach. The methodology ensures that the FRFM captures diverse aspects of image quality while maintaining alignment with human evaluations.

\subsection{Normalization}

To ensure comparability, the selected metrics were normalized to a common scale using min-max normalization:
\[
M_i^{\text{norm}} = \frac{M_i - M_{\text{min}}}{M_{\text{max}} - M_{\text{min}}}
\]
where \(M_i\) is the metric score, and \(M_{\text{min}}\) and \(M_{\text{max}}\) are the minimum and maximum scores, respectively.

\subsection{Weight Assignment}

Weights were assigned to each metric based on its correlation coefficient with MOS data:
\[
w_i = \frac{\rho_i}{\sum_{j=1}^{n} \rho_j}
\]
where \(w_i\) is the weight for metric \(i\), and \(\rho_i\) is its correlation coefficient.

\subsection{Fusion Equation}

The overall quality score \(Q\) was computed as a weighted sum of the normalized metric scores:
\[
Q = \sum_{i=1}^{n} w_i \cdot M_i^{\text{norm}}
\]
This equation ensures that metrics with higher correlations contribute more to the final quality score.

\section{Validation of the FRFM}

The FRFM was validated using unseen images from the dataset. The validation process involved:
\begin{itemize}
    \item \textbf{Correlation with MOS:} The FRFM’s scores were compared with MOS values to assess alignment.
    \item \textbf{Comparison with Baseline Metrics:} The FRFM was benchmarked against individual metrics such as SSIM and LPIPS.
    \item \textbf{Evaluation on Steganography:} The metric's performance was tested on steganography-encoded images, where traditional metrics often fail.
\end{itemize}

\subsection{Performance Metrics}

The validation included:
\begin{itemize}
    \item Pearson and Spearman correlations to measure linear and rank-based relationships with MOS.
    \item Root Mean Squared Error (RMSE) to evaluate prediction accuracy.
    \item Visual examples to qualitatively assess the metric's ability to detect perceptual artifacts.
\end{itemize}

The results demonstrated that the FRFM outperformed traditional metrics, particularly in scenarios involving subtle distortions and steganography. The next chapter discusses the extension of the FRFM to a No-Reference Metric (NRM) for real-world applications.
