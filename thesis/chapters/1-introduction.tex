\chapter{Introduction}\label{chap:introduction}

\section{Contextualization}\label{sec:contextualization}

Image quality refers to the degree to which a visual representation meets perceptual or functional expectations. It is typically associated with the presence or absence of distortions, artifacts, or degradations that affect how an image is perceived by humans or processed by machines~\cite{wang_bovik_modern_iqa_2006, thung_survey_iqa, ComprehensiveEvaluation2019}. High-quality images preserve structural, textural, and color information in a way that aligns with human visual preferences or supports reliable computer vision performance~\cite{sheikh_vif_2006, zhang_lpips_2018}.

Image Quality Assessment (IQA) is the process of quantifying image quality in a systematic and reproducible way. It plays a central role in optimizing image acquisition~\cite{ciancio_blur_assessment_2011}, compression~\cite{wang_no_reference_jpeg_2002}, transmission~\cite{engelke_wireless_iqa_2010}, and restoration pipelines~\cite{dabov_bm3d_2007}. IQA methods aim to provide reliable quality estimates that correlate well with human perception~\cite{wang_ssim_2004, FullReference2024}. Due to the complexity of human vision and its subjective nature, building computational models that accurately reflect perceived quality remains a challenging task.

IQA methods are generally categorized as subjective or objective. Subjective assessment involves human observers who rate the perceived quality of images, typically following standardized protocols such as ITU-R BT.500~\cite{itu_bt500_2023}. While subjective methods are considered the gold standard due to their direct alignment with human perception, they are time-consuming, expensive, and not scalable. In contrast, objective methods rely on computational models to estimate image quality automatically, aiming to approximate human judgment with high consistency and low cost~\cite{zaric_comparison_objective_subjective, sheikh_vif_2006}.

Subjective image quality assessment relies on human evaluations to generate ground-truth perceptual scores, often in the form of Mean Opinion Scores (MOS) or Difference Mean Opinion Scores (DMOS). These scores are typically collected under controlled conditions following international standards such as ITU-R BT.500~\cite{itu_bt500_2023} or ITU-T P.910~\cite{itu_p910_2008}. Subjective assessment captures nuances of human vision that are difficult to model algorithmically, making it essential for validating and benchmarking objective IQA models~\cite{ponomarenko_tid2013, zaric_comparison_objective_subjective}. However, it is inherently limited by inter-observer variability, cultural or demographic bias, and the logistical costs associated with large-scale studies~\cite{ghadiyaram_crowdsourced_study_2016}. Crowdsourcing platforms like Amazon Mechanical Turk~\cite{amazon_mturk} have recently enabled more scalable data collection, though at the expense of environmental control and consistency.


Objective IQA methods are commonly divided into three categories: full-reference (FR), reduced-reference (RR), and no-reference (NR). FR-IQA assumes access to an undistorted reference image and compares it to the distorted version using perceptual models~\cite{wang_ssim_2004, sheikh_ifc_2005, zhang_fsim_2011}. RR-IQA methods extract partial information from the reference image, enabling a compromise between performance and practicality~\cite{wang_wavelet_statistics_2005, li_divisive_normalization_2009}. NR-IQA, also known as blind IQA, operates without any reference and is considered the most challenging, requiring models to infer quality based solely on the distorted image~\cite{mittal_brisque_2012, bosse_deep_nriqa_2018}.


Facial Image Quality Assessment (FIQA) is a specialized subfield of IQA that aims to quantify the quality of facial images with respect to their utility in downstream biometric or analytic tasks. Unlike general-purpose IQA, FIQA must account for both perceptual attributes (e.g., blur, noise) and task-specific considerations such as facial pose, occlusion, expression, and alignment~\cite{hernandez_fiqanet_2020, boutros_iqface_2021, li_biofacenet_2021}. High-quality face images are crucial for ensuring the accuracy and fairness of face recognition systems, particularly in security, forensics, and surveillance domains~\cite{xu_secureqnet_2020, luo_deepiq_2018}. Consequently, FIQA models often incorporate features from deep face recognition networks to align quality predictions with identity discrimination performance~\cite{FaceMetric2025}. This task-oriented nature of FIQA makes it fundamentally different from traditional perceptual quality assessment.

FIQA systems have been shown to produce different quality scores depending on a person's age, gender, or skin tone~\cite{jo_ifqa_2024, FaceMetric2025}. These differences often happen because the training data includes more examples from certain groups and fewer from others. For example, images of people with darker skin or non-frontal poses are often less common in training sets, which leads to lower quality scores for those individuals~\cite{kanwisher2006fusiform}. This can cause face recognition systems to perform worse for some groups than others, raising serious concerns about fairness.

The International Civil Aviation Organization~\cite{icao_2015} (ICAO) and the ISO/IEC 19794--5 standard~\cite{iso_iec29794-5_2010} establish guidelines for image quality in Machine-Readable Travel Documents (MRTDs). These guidelines ensure uniform image conditions (e.g., lighting, focus, and resolution) and consistency across datasets. While these regulations establish a technical baseline, they do not account for perceptual biases and demographic variability in FIQA.\@

The ethical implications of these biases are profound. Political regulations, such as the European Convention on Human Rights (Article 14)~\cite{echr_article14}, the Universal Declaration of Human Rights (Article 7)~\cite{udhr_article7}, the General Data Protection Regulation (Article 22)~\cite{gdpr_article22}, and emerging AI governance frameworks, such as the European Artificial Intelligence Act (2024)~\cite{eu_ai_act_2024} and proposals in the USA~\cite{us_ai_bill_rights_2022}, aim to prevent discriminatory decisions. Despite these efforts, biases persist, often introduced through the human observers who evaluate facial images for FIQA algorithms.

Evidence from neuroscience further supports the complexity of facial image perception. The fusiform face area, a specialized region in the human brain, is selectively activated by face stimuli~\cite{kanwisher2006fusiform, tsao2008mechanisms}. This biological specialization makes FIQA particularly sensitive to both stimulus features (e.g., age, gender, ethnicity, attractiveness) and the demographic background of the observers.

An even greater challenge arises when evaluating the quality of steganographically distorted facial images. Steganography is the practice of concealing information within digital media, typically by subtly modifying pixel values in a way that is imperceptible to human observers~\cite{steganography}. Although visually unobtrusive, these alterations can degrade biometric features and compromise recognition performance. NR-IQA approaches, while not requiring references, are generally not designed to detect such imperceptible, task-relevant distortions.

A particularly relevant subclass of steganography for identity documents is printer-proof steganography, which embeds information in a way that remains intact through the print-scan process~\cite{codeface2021, stegastamp2020}. These techniques aim to survive real-world transformations such as color shifts, compression, and physical degradation, while maintaining visual fidelity. However, even when such methods are visually imperceptible, they can induce subtle frequency-domain changes or spatial artifacts that disrupt face recognition systems. Assessing image quality in this context requires NR-IQA methods that are sensitive not only to perceptual degradation but also to recognition-relevant cues.


\section{Problem Statement}\label{sec:problem_statement}

Despite significant advances in FIQA, current approaches struggle to capture task-specific degradations introduced by modern steganographic techniques. Existing methods often rely on handcrafted features~\cite{henniger2020biosig}, supervised quality learning~\cite{hernandez2019faceqnet, meng2021magface, terhorst2020serfiq}, or rank-based formulations~\cite{liu2017rankiqa}. However, these frameworks are typically trained on standard datasets and are not optimized to handle distortions that preserve visual fidelity while disrupting biometric utility. Moreover, demographic and perceptual biases embedded in training data~\cite{babnik2022} raise concerns about the fairness and generalizability of FIQA systems. This is especially problematic for applications involving MRTDs, where regulation mandates consistent quality but does not address ethical or perceptual variance~\cite{icao_2015, iso_iec29794-5_2010}. Therefore, there is a critical need for NR-IQA methods that can detect subtle, high-impact degradations in facial images, particularly those arising from adversarial steganography while accounting for demographic fairness and interpretability.

Traditional IQA frameworks tend to generalize across domains, but real-world applications demand task-aware assessment strategies. In the context of facial biometrics, image quality must be evaluated not only in terms of visual fidelity but also in terms of its impact on recognition performance and fairness. This motivates the development of application-specific IQA pipelines that consider context-dependent factors, such as demographic variability and task utility. At the same time, the perceptual dimension of image quality remains central. Human observers are still used as the ground truth in subjective assessments~\cite{ITU-R-BT500, mos2016}, yet NR-IQA models often diverge from these judgments, especially in complex scenarios involving subtle degradations or diverse populations. To bridge this gap, new strategies are needed to align NR-IQA with subjective perception—either by integrating perceptual priors, modeling bias sources, or learning from pseudo-MOS annotations that reflect human preferences~\cite{chen2021pseudo, jin2020pipal}.

To address the limitations of existing approaches, we propose a NR-IQA framework tailored to facial images affected by subtle or task-relevant distortions, such as those introduced by steganography. Our method relies on a fusion strategy that combines multiple FR metrics, trained using supervised regression against a curated set of subjective scores. This fused metric serves as a proxy ground truth to guide the learning of a NR-IQA model, enabling it to approximate perceptual quality without requiring access to pristine reference images. The framework is evaluated across a steganographically augmented dataset of facial images, incorporating multiple embedding levels and distortion types. By integrating perceptual fidelity, recognition utility, and robustness to imperceptible alterations, the proposed approach seeks to bridge the gap between human perception and automatic assessment.
