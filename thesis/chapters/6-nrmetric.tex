\chapter{No-Reference Metric Design}

\section{Introduction}

While Full-Reference metrics like the FRFM require a pristine reference image, real-world applications often lack such references. This limitation necessitates the development of No-Reference Metrics (NRMs), which assess image quality directly from distorted images. This chapter outlines the design and implementation of an NRM based on the FRFM, leveraging neural networks to generalize the metric to reference-free scenarios.

\section{Training Framework}

The NRM is developed using the FRFM scores as ground truth, enabling the model to learn perceptual quality evaluation without relying on reference images.

\subsection{Dataset Preparation}

The dataset for training the NRM consists of:
\begin{itemize}
    \item \textbf{Input:} Steganography-encoded images with diverse distortions.
    \item \textbf{Target:} FRFM scores computed for each image.
\end{itemize}
Data augmentation techniques, such as random cropping, scaling, and color adjustments, are applied to increase dataset diversity and improve model robustness.

\subsection{Model Architecture}

The NRM employs a convolutional neural network (CNN) architecture, optimized for image quality assessment tasks:
\begin{itemize}
    \item \textbf{Input Layer:} Accepts distorted images resized to a fixed resolution.
    \item \textbf{Convolutional Layers:} Extract low- and high-level features, focusing on distortions in key regions.
    \item \textbf{Fully Connected Layers:} Combine extracted features to predict a single quality score.
    \item \textbf{Output Layer:} Produces a scalar value representing the predicted quality score.
\end{itemize}
The model is implemented using PyTorch, with hyperparameters fine-tuned through cross-validation.

\subsection{Loss Function}

The model is trained using a regression loss function to minimize the difference between predicted and ground truth FRFM scores:
\[
\mathcal{L} = \frac{1}{N} \sum_{i=1}^{N} (Q_i^{\text{predicted}} - Q_i^{\text{true}})^2
\]
where \(Q_i^{\text{predicted}}\) is the predicted score and \(Q_i^{\text{true}}\) is the FRFM score for the \(i\)-th image.

\section{Validation and Testing}

The NRM is validated on a held-out dataset to ensure its generalizability and robustness.

\subsection{Evaluation Metrics}

The following metrics are used to evaluate the NRM’s performance:
\begin{itemize}
    \item \textbf{Correlation Coefficients:} Pearson and Spearman correlations between predicted scores and MOS values.
    \item \textbf{Root Mean Squared Error (RMSE):} Measures the accuracy of the predictions.
    \item \textbf{Rank Consistency:} Assesses the NRM’s ability to preserve relative rankings of image quality.
\end{itemize}

\subsection{Qualitative Evaluation}

Visual examples are used to assess the NRM’s ability to detect perceptual artifacts. Examples include:
\begin{itemize}
    \item Images with localized distortions, such as artifacts in facial regions.
    \item Steganography-encoded images with subtle embedding artifacts.
\end{itemize}

The NRM demonstrates strong alignment with MOS values, achieving high correlation and low error rates. Its ability to detect perceptual distortions without reference images makes it suitable for real-world applications, including facial image quality assessment and secure communications.

The next chapter presents the results of the experiments, comparing the performance of the FRFM and NRM against baseline metrics and subjective evaluations.
