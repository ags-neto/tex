\section{Related Work}

Several fusion-based approaches have been proposed to better align IQA metrics with human perception. Liu et al.~\cite{liu2013mmf} introduced a multi-method fusion framework in which multiple FR-IQA scores are linearly combined through regression to better approximate human judgments. Similarly, Henniger et al.~\cite{henniger2020biosig} developed a Random Forest model trained on handcrafted image features drawn from ISO face quality standards, improving predictive utility for biometric applications. These works show that fusing complementary quality cues improves correlation with MOS compared to single-metric methods

In the absence of subjective labels, several methods have adopted weakly supervised strategies based on pseudo-labels. Chen et al.~\cite{chen2021pseudo} generated pseudo-MOS scores by averaging multiple FR-IQA scores. RankIQA~\cite{liu2017rankiqa} used synthetic degradations and ranking-based supervision to learn ordinal quality relationships. Wu et al.~\cite{wu2020cnn} trained cascaded CNN regressors on pseudo-MOS to support NR-IQA training. These methods show that pseudo-labeling can guide deep quality models when ground-truth MOS is limited.

Recent NR-IQA methods leverage deep features from CNNs pretrained on large datasets. Kang et al.~\cite{kang2014cnn} showed that CNNs can directly predict image quality from patches. In FIQA, SER-FIQ\cite{terhorst2020serfiq} (Stochastic Embedding Robustness for Face Image Quality) estimates quality by measuring the consistency of face embeddings under dropout. MagFace~\cite{meng2021magface} links embedding magnitude to recognition performance to learn quality-aware features. FaceQnet~\cite{hernandez2019faceqnet} estimates how well a face image will perform in recognition tasks, using a regression model trained on features from a pre-trained network. QualFace~\cite{tremoco2021qualface} adapts face recognition networks for document images and adds a quality estimation branch aligned with ICAO and ISO/IEC standards. These approaches replace handcrafted indicators with learned representations optimized for face recognition.

Other studies emphasize that image quality is inherently task-specific. In FIQA, quality is defined not by visual aesthetics but by its effect on recognition performance. Standards such as ISO/IEC 19794--5 codify this operational perspective, specifying conditions for acceptable biometric image acquisition. Datasets such as PIPAL~\cite{pipal} and TID2013~\cite{tid2013}, which include generative distortions, further highlight the need for context-specific IQA evaluation. Our work follows this trajectory by targeting steganographically degraded facial images, an emerging use case not addressed in current FIQA literature.
