\section{Introduction}

Image Quality Assessment (IQA) plays a critical role in domains such as biometric authentication, multimedia processing, and medical imaging~\cite{kim2015face, huang2020facerecon}. It broadly refers to the estimation of visual quality based on attributes like contrast, sharpness, noise, and the presence of artifacts. Within this domain, Facial Image Quality Assessment (FIQA) focuses specifically on facial images, where quality is not assessed in terms of visual aesthetics, but rather in terms of its impact on the performance of face recognition systems~\cite{cavazos2021racebias, terhoerst2020demobias}.

IQA methods fall into two categories: subjective and objective. Subjective methods use human ratings to measure perceived quality, often summarized as Mean Opinion Scores (MOS)~\cite{ITU-R-BT500}. These scores are reliable but expensive to collect and not scalable. Objective methods rely on algorithms to estimate quality, either by comparing to a reference image or by analyzing features of the image itself.

Objective methods can be divided into full-reference (FR) and no-reference (NR). FR methods compare a distorted image to a clean reference. They are often accurate but can only be used when a reference is available. NR methods estimate quality without a reference and are more practical in real-world settings, though they often struggle to generalize across distortions and content~\cite{shahrukh2019survey}.

FIQA is a subdomain of IQA focused on facial images. It plays a key role in biometric applications such as identity verification, where reference images are typically unavailable, and is also relevant in non-biometric scenarios like surveillance and forensic analysis. Consequently, most FIQA methods are no-reference NR, relying on task-specific priors or learned representations to estimate image quality~\cite{hernandez2019faceqnet}.

A key challenge in IQA is the gap between objective metrics and human perception. Classical metrics such as PSNR~\cite{gonzalez2002digital} (Peak Signal-to-Noise Ratio), SSIM~\cite{wang2004ssim} (Structural Similarity Index), and VIF~\cite{sheikh2006image} (Visual Information Fidelity) provide automatic quality estimates but often show weak correlation with human ratings across datasets~\cite{shahrukh2019survey}. This issue is more pronounced in facial images, where perceived quality is shaped by both image distortions and biases from the observer.

Studies have shown that FIQA is affected by both demographic and non-demographic biases. Perceived quality can vary with ethnicity, gender, or age, often due to dataset imbalance and observer subjectivity~\cite{cavazos2021racebias, terhoerst2020demobias, kabbani2024demo}. For example, darker skin tones tend to produce lower recognition accuracy, and female faces are often rated with lower quality scores~\cite{huang2020facerecon}. These effects highlight the need for more inclusive and perceptually aligned quality metrics.

The International Civil Aviation Organization~\cite{icao-2015} (ICAO) and the International Organization for Standardization (ISO) and the International Electrotechnical Commission (IEC) 19794--5 standard~\cite{iso-iec29794-5-2010} establish guidelines for image quality in Machine-Readable Travel Documents (MRTDs). These guidelines ensure uniform image conditions (e.g., lighting, focus, and resolution) and consistency across datasets. While these regulations establish a technical baseline, they do not account for perceptual biases and demographic variability in FIQA.\@

These biases raise ethical concerns. Legal frameworks, such as the European Convention on Human Rights (Article 14)~\cite{echr-article14}, the Universal Declaration of Human Rights (Article 7)~\cite{udhr-article7}, the General Data Protection Regulation (Article 22)~\cite{gdpr-article22}, the European Artificial Intelligence Act (2024)~\cite{eu-ai-act-2024} and the United States Bill of Rights~\cite{us-ai-bill-rights-2022}, aim to prevent discriminatory decisions. Still, biases persist, often introduced through human observers involved in labeling.

Neuroscience shows that face perception relies on the fusiform face area, a brain region specialized for facial stimuli~\cite{kanwisher2006fusiform, tsao2008mechanisms}. This biological specialization makes FIQA particularly sensitive to both stimulus features (e.g., age, gender, ethnicity, attractiveness) and the demographic background of the observers.

Steganographically distorted facial images pose a harder problem. Steganography hides data by slightly changing pixel values, often in ways that escape human detection~\cite{steganography}. Recent printed-proof techniques go further by ensuring that hidden data can survive physical printing and scanning noises, making them useful for secure document encoding. While these changes are visually minimal, they can damage biometric features and reduce recognition accuracy~\cite{stegastamp2020, codeface2021, stampone2024, riemannian2023}. NR methods are usually not designed to catch these small but critical degradations.

To handle these limitations, we propose a FIQA framework based on pseudo-MOS.\@ We first use a small set of facial images labeled with overall quality scores to train a fusion model that combines FR metrics into a single predictor. This model generates pseudo-MOS for the rest of the dataset. Using these labels, we then train a NR deep regressor based on a ResNet-18~\cite{resnet} pretrained on ImageNet~\cite{imagenet}, allowing it to estimate perceptual quality without needing a reference image.

Our approach bridges the gap between FR supervision and NR inference. It offers a scalable solution for evaluating images with subtle distortions, like steganography, and supports the development of quality assessment models tailored to domain-specific tasks. In doing so, it combines the accuracy of FR metrics with the practicality of NR models in a single IQA pipeline.
