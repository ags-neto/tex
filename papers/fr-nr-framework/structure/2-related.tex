\section{Related Work}

To improve perceptual alignment, several fusion-based IQA methods have been proposed. Liu et al.~\cite{liu2013mmf} introduced a multi-method fusion (MMF) framework in which multiple FR-IQA scores are linearly combined through regression to better approximate human judgments. Similarly, Henniger et al.~\cite{henniger2020biosig} developed a Random Forest model trained on handcrafted image features drawn from ISO face quality standards, improving predictive utility for biometric applications. Fusion models demonstrate that integrating complementary quality cues yields superior MOS correlation compared to standalone metrics~\cite{Robinson2020}.

Beyond full-reference settings, the scarcity of ground-truth subjective scores has prompted the development of weakly supervised approaches based on pseudo-labels. Chen et al.~\cite{chen2021pseudo} proposed generating pseudo-MOS scores by averaging outputs from several FR-IQA metrics. RankIQA~\cite{liu2017rankiqa} employed synthetic degradations and relative ranking supervision to learn ordinal quality relationships. Wu et al.~\cite{wu2020cnn} used cascaded CNN regressors trained on pseudo-MOS to bootstrap NR-IQA learning. These approaches confirm the viability of pseudo-supervision in training deep IQA models when human MOS labels are limited or unavailable.

Recent progress in NR-IQA has been driven by the use of deep features from CNNs pretrained on large datasets. Kang et al.~\cite{kang2014cnn} showed that CNNs can directly regress quality scores from image patches. In the domain of FIQA, techniques such as SER-FIQ~\cite{terhorst2020serfiq} exploit the dropout-based variability of face embeddings as a proxy for image quality, while MagFace~\cite{meng2021magface} learns quality-aware facial representations by correlating embedding norms with recognition utility. QualFace~\cite{tremoco2021qualface} adapts deep face recognition models to conform with ICAO and ISO/IEC document standards, introducing an explicit quality estimation module for ID and travel document verification. These methods mark a shift from handcrafted quality indicators to learned feature-level representations tailored to face recognition tasks.


Other studies emphasize that image quality is inherently task-specific. In FIQA, quality is defined not by visual aesthetics but by its impact on face recognition performance. Standards such as ISO/IEC 19794--5 codify this operational perspective, specifying conditions for acceptable biometric image acquisition. Supervised models like FaceQnet~\cite{hernandez2019faceqnet} learn to predict face utility scores directly from embeddings. Datasets such as PIPAL~\cite{jin2020pipal}, which include generative distortions, further highlight the need for context-specific IQA evaluation. Our work follows this trajectory by targeting steganographically degraded facial images, an emerging use case not addressed in current FIQA literature.
