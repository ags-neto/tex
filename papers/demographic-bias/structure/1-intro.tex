\section{Introduction}

The evaluation of image quality is essential in applications such as biometric authentication, multimedia processing, and medical imaging~\cite{Kim2015, Huang2020}. In the specific domain of facial image quality assessment (FIQA), the goal is to ensure that images used for face recognition (FR) systems meet a quality standard that optimizes recognition performance~\cite{Cavazos2021}. Unlike traditional image quality assessment (IQA), which considers general visual attributes such as contrast, sharpness, and noise levels, FIQA focuses on assessing image quality in a manner that directly impacts face recognition accuracy~\cite{Terhoerst2020}. 

A fundamental challenge in FIQA lies in the discrepancy between objective image quality metrics and human perception, typically quantified through mean opinion scores (MOS). MOS is an aggregate measure obtained from subjective evaluations by human observers~\cite{ITU-R-BT500}. While existing IQA metrics such as peak signal-to-noise ratio~\cite{gonzalez2002digital} (PSNR), structural similarity index measure~\cite{wang2004image} (SSIM), and visual information fidelity~\cite{sheikh2006image} (VIF) provide automated assessments of image quality, their correlation with MOS remains inconsistent across datasets~\cite{Babnik2022}. This misalignment is particularly problematic in facial image analysis, where the perceptual quality of an image may be influenced by both intrinsic image distortions and extrinsic observer biases. 

A significant body of research has identified demographic and non-demographic biases in FIQA, where factors such as ethnicity, age, and gender influence the subjective perception of image quality~\cite{Kabbani2024, 9304865, Cavazos2021, tapia2024beauty}. These biases arise from the overrepresentation of specific demographic groups in training datasets, as well as perceptual differences across observers. Prior studies have shown that FR accuracy is lower for dark-skinned individuals due to dataset imbalances, while female faces tend to receive lower quality scores in FIQA evaluations~\cite{Huang2020}. The existence of these biases underscores the need for a more robust and inclusive approach to IQA that accounts for variations in human perception.

The International Civil Aviation Organization~\cite{icao_2015} (ICAO) and the ISO/IEC 19794--5 standard~\cite{iso_iec29794-5_2010} establish guidelines for image quality in Machine-Readable Travel Documents (MRTDs). These guidelines ensure uniform image conditions (e.g., lighting, focus, and resolution) and consistency across datasets.
While these regulations establish a technical baseline, they do not account for perceptual biases and demographic variability in FIQA.\@

FIQA metrics are optimized for deep-learning-based verification systems rather than regulatory compliance. In ICAO-compliant documents, such as passports and national ID cards, strict quality criteria—including lighting, background uniformity, and sharpness—must be met, irrespective of biometric matching accuracy. This distinction becomes even more critical when facial images are embedded with printer-proof steganographic security features, which may introduce visual patterns that degrade FIQA scores despite maintaining ICAO compliance. These observations suggest that current FIQA alone is insufficient for assessing document image quality, necessitating a more robust approach that integrates multiple IQA methodologies.

The ethical implications of these biases are profound. Political regulations, such as the European Convention on Human Rights (Article 14)~\cite{echr_article14}, the Universal Declaration of Human Rights (Article 7)~\cite{udhr_article7}, the General Data Protection Regulation (GDPR, Article 22)~\cite{gdpr_article22}, and emerging AI governance frameworks, such as the European Artificial Intelligence Act (2024)~\cite{eu_ai_act_2024} and proposals in the USA~\cite{us_ai_bill_rights_2022}, aim to prevent discriminatory decisions. Despite these efforts, biases persist, often introduced through the human observers who evaluate facial images for FIQA algorithms.

Research in neuroscience and psychology suggests that this phenomenon is rooted in the unique processing of facial images by the human brain. The fusiform face area (FFA), a specialized brain region, is particularly tuned to recognizing and evaluating faces~\cite{kanwisher2006fusiform, tsao2008mechanisms}. This specialization makes facial image quality assessment a complex task, influenced by both the demographic and non-demographic characteristics of the faces (e.g., age, gender, ethnicity, attractiveness) and the demographics of the observers (e.g., age, gender, ethnicity).

To address these challenges, this study explores a fusion-based approach to improve the correlation between IQA metrics and MOS.\@ By integrating multiple IQA metrics, the goal is to create an optimized metric that more accurately reflects subjective human assessments. The primary contributions of this work are threefold. First, we rank individual IQA metrics based on their correlation with MOS using Pearson's linear correlation coefficient (PLCC) and Spearman's rank-order correlation coefficient (SRCC). Second, we compare different fusion techniques, including principal component analysis (PCA), regression models, and machine learning-based approaches, to determine the most effective method for enhancing MOS predictability. Third, we analyze the impact of observer demographics on MOS ratings to evaluate the extent of bias in FIQA methodologies. 

This study provides a comprehensive evaluation of 41 IQA metrics, highlighting their strengths and weaknesses in aligning with human perception. Our findings demonstrate that fusion-based IQA models significantly improve MOS predictability, with random forest-based fusion outperforming linear and PCA-based methods. The results emphasize the necessity of incorporating perceptual biases into IQA frameworks to develop more accurate and equitable image quality assessment methodologies. 
